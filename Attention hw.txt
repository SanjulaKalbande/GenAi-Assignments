The attention model which was proposed by Vasani et al. introduced a new function previous to this the CNN and the RNNs were used for NLP, which was the attention function which consisted of query, and key value pairs which assigned the weights onto the words of the sentence and the key, values, and output everything is in form of vectors. I found out that the attention is similar to the weighted graph  There are multiple types of attention models: self-attention and multiheaded attention. The transformer has two parts one is encoder and other is decoder.